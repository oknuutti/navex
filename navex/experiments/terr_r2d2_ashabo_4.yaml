search:
  method: 'asha-bo'
  resume: ''
  metric: 'tot_ratio'
  mode: 'max'
  samples: 243
  nodes: 6
  node_types: 'volta'   # volta for triton, type_gpu for csc

  # doesnt really work to have different cpu counts as tune.run(..., resources_per_trial={"cpu":...}) needs to be set
  node_type_cpus: '8'
  grace_period: 1500    # for asha only
  reduction_factor: 3   # for asha only
  username: ''
  keyfile: ''
  proxy: ''
  host: ''
  port: 0

training:
  trial: 'terr'
  name: 'v0'
  cache: 'cache'
  output: 'output'
  batch_size: 8
  batch_mem: 32000
  gpu: 1
  epochs: 24001   # actually steps
  print_freq: 5
  test_freq: 1500
  save_freq: 1
  resume: null
  evaluate: 0
  pretrained: ''
  early_stopping: 0
  reduced_precision: 0
  auto_lr_find: 0
  deterministic: 1

model:
  arch: 'r2d2-own_vgg'
  in_channels: 1
  partial_residual: 0   # not in use
  width_mult: 1.0
  pretrained: 0         # not in use
  cache_dir: 'cache'    # not in use
  des_head:
    dimensions:  128
    hidden_ch:   0
    exp_coef:    0.0
    use_se:      0
    dropout:     0.0
  det_head:
    after_des:   1
    hidden_ch:   0
    exp_coef:    0.0
    use_se:      0
    dropout:     0.0
  qlt_head:
    skip:        0
    after_des:   1
    hidden_ch:   0
    exp_coef:    0.0
    use_se:      0
    dropout:     0.0

loss:
  loss_type: thresholded
  wdt: -1.5       # weight for peakiness and cosim losses
  wap: -2.0       # weight for expected ap loss
  wqt: -1.0
  det_n: !h_tune2_choice  '[32], [16, 24, 32, 48, 64]'     # detector neighbourhood size
  base: 0.1       # quality loss target mAP
  nq: 20          # quantizer bins for ap calc
  sampler:        # was for a descriptor head that is same resolution than input image of size [192, 192]
    pos_d: !h_tune2_randint  '(3, 4), (1, 6)'   # was 3       # positive samples generated up to this far from ideal location
    neg_d: !h_tune2_randint  '(6, 7), (5, 16)'  # was 5       # negative samples generated starting from distance from ideal location
    ngh:   2      # was 7       # neighbourhood size in descriptor cells
    subd:  1      # was 1       # neigbourhood sampling interval
    border: 16    # was 16
    subq: -8      # was -8      # grid step size for positive samples
    subd_neg: -8  # was -8      # grid step size for generating additional negative samples
    max_neg_b: 8                # distractors mined from max this number of images from same batch
    maxpool_pos: 1              # False: use all positive samples, or True: only the best matching one

optimizer:
  method: 'adam'
  learning_rate: 0.0003    # for some reason cant use exp form, e.g. 3e-4
  weight_decay:  !h_tune2_loguniform  '(4e-4, 6e-4), (1e-8, 1e-3)'
  split_params:  0
  eps:           1e-8   # tried to optimize, doesn't seem to affect much

data:
  max_sc:    1.091  # 2**(1/8), half of scale steps used during extraction, i.e. 2**(1/4)
  max_rot:   !h_tune2_uniform '(4.5, 5.5), (0.0, 10.0)'    # in degrees, synth pair warp related
  max_shear: 0.0    # synth pair warp related
  max_proj:  !h_tune2_uniform '(0.45, 0.55), (0.20, 0.80)'    # synth pair warp related
  noise_max: !h_tune2_uniform '(0.08, 0.12), (0.00, 0.20)'
  rnd_gain:  1.2        # tried to optimize, doesn't seem to affect much
  image_size: 224
  path: 'data/aachen.tar;data/revisitop1m.tar'
  npy: 'false'
  trn_ratio: 0.85
  val_ratio: 0.10
  tst_ratio: 0.05
  workers: 8
