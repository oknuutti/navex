search:
  samples: 4
  workers: 2
  grace_period: 2
  reduction_factor: 4

training:
  name: 'v0'
  cache: 'c:/project-data/navex/cache'
  output: 'd:/projects/navex/output'
  batch_size: 16
  acc_grad_batches: 1
  gpu: 1
  epochs: 30
  print_freq: 1
  test_freq: 1
  save_freq: 1
  resume: null
  evaluate: 0
  pretrained: ''
  early_stopping: 3
  reduced_precision: 1
  auto_lr_find: 0
  deterministic: 1

model:
  arch: 'own_vgg'
  head_conv_ch: !h_tune_choice    '[128, 256, 512]'
  descriptor_dim: 256    # try lower values
  width_mult: 1.0        # try lower values
  dropout: !h_tune_quniform       '0.0, 0.3, 0.1'
  batch_norm: !h_tune_choice      '[0, 1]'
  excl_bn_affine: !h_tune_sample_from  'lambda spec: spec.config.batch_norm * tune.choice([0,1])'
  direct_detection: 0    # not implemented
  pretrained: 0          # not implemented
  cache_dir: 'c:/project-data/navex/cache'

loss:
  wp: 1.0         # peakiness loss weight    # TODO: optimize during training
  wc: 1.0         # cosim loss weight        # TODO: optimize during training
  wa: 1.0         # ap loss weight           # TODO: optimize during training
  det_n: !h_tune_choice    '[12, 16, 20]'       # detector neighbourhood size
  base: !h_tune_quniform   '0.45, 0.65, 0.05'     # quality loss target mAP
  nq: 20          # quantizer bins for ap calc
  sampler:        # was for descriptor head output size [192, 192]
    ngh: 4        # was 7       # neighbourhood size in descriptor cells
    subq: -3      # was -8      # grid step size for positive samples
    subd: 1       # was 1       # neigbourhood sampling interval
    pos_d: 1      # was 2       # positive samples generated up to this far from ideal location
    neg_d: 3      # was 5       # negative samples generated starting from distance from ideal location
    border: 4     # was 16
    subd_neg: -6  # was -8      # grid step size for generating additional negative samples
    max_neg_b: 4                # distractors mined from max this number of images from same batch
    maxpool_pos: 1              # False: use all positive samples, or True: only the best matching one

optimizer:
  method: 'adam'
  learning_rate: !h_tune_qloguniform  '5e-5, 1e-3, 5e-5'
  weight_decay: !h_tune_qloguniform   '1e-5, 1e-4, 1e-5'
  split_params: !h_tune_choice        '[0, 1]'
  excl_bn: 0
  eps: !!float 1e-8

data:
  path: 'aachen'
  trn_ratio: 0.8
  val_ratio: 0.1
  tst_ratio: 0.1
  workers: 3
